# SW Engineer - IMPLEMENTATION State Rules

## State Context
You are actively implementing code for an effort, following the implementation plan and maintaining quality standards.

┌─────────────────────────────────────────────────────────────────┐
│ RULE R106.0.0 - IMPLEMENTATION Rules                           │
│ Source: rule-library/RULE-REGISTRY.md#R106                     │
├─────────────────────────────────────────────────────────────────┤
│ IMPLEMENTATION PROTOCOL:                                       │
│ 1. Follow implementation plan exactly as specified            │
│ 2. Measure size every 200 lines of code added                 │
│ 3. Write tests alongside implementation                        │
│ 4. Update work log with progress every 30-60 minutes          │
│ 5. Stop immediately if approaching 800-line limit             │
│ 6. Commit frequently with descriptive messages                │
└─────────────────────────────────────────────────────────────────┘

## Size Monitoring During Implementation

┌─────────────────────────────────────────────────────────────────┐
│ RULE R007.0.0 - Size Limit Enforcement                        │
│ Source: rule-library/RULE-REGISTRY.md#R007                     │
├─────────────────────────────────────────────────────────────────┤
│ SIZE MONITORING REQUIREMENTS:                                  │
│                                                                 │
│ ⚠️ CRITICAL: Use ONLY tmc-pr-line-counter.sh tool            │
│ ⚠️ NEVER count lines manually or with other tools            │
│ ⚠️ Exclude generated code (zz_generated*, *.pb.go, CRDs)     │
│                                                                 │
│ MEASUREMENT SCHEDULE:                                          │
│ - Every 200 lines of implementation code added                │
│ - Before committing significant changes                       │
│ - When implementation feels "substantial"                     │
│ - If approaching complexity milestones                        │
│                                                                 │
│ RESPONSE TO SIZE WARNINGS:                                     │
│ - At 600 lines: Start planning completion strategy            │
│ - At 700 lines: Consider code optimization                    │
│ - At 750 lines: STOP and prepare for potential split         │
│ - At 800 lines: IMMEDIATE STOP - transition to MEASURE_SIZE   │
└─────────────────────────────────────────────────────────────────┘

```bash
#!/bin/bash
# Size monitoring during implementation

BRANCH=$(git branch --show-current)
LINES=$(/workspaces/kcp-shared-tools/tmc-pr-line-counter.sh -c "$BRANCH" | tail -1)
TIMESTAMP=$(date '+%Y-%m-%d %H:%M:%S')

echo "[$TIMESTAMP] Implementation size check: $LINES lines"

# Log to work log
echo "- [$TIMESTAMP] Size check: $LINES lines" >> work-log.md

if [ "$LINES" -ge 750 ]; then
    echo "🚨 CRITICAL: Approaching size limit ($LINES/800 lines)"
    echo "STOP implementation and prepare for MEASURE_SIZE state"
    exit 1
elif [ "$LINES" -ge 700 ]; then
    echo "⚠️ WARNING: High line count ($LINES/800 lines)"
    echo "Consider code optimization and completion strategy"
elif [ "$LINES" -ge 600 ]; then
    echo "📊 INFO: Substantial progress ($LINES/800 lines)"
    echo "Plan completion strategy to stay under limit"
fi
```

## Test-Driven Implementation

┌─────────────────────────────────────────────────────────────────┐
│ RULE R060.0.0 - Test Implementation                            │
│ Source: rule-library/RULE-REGISTRY.md#R060                     │
├─────────────────────────────────────────────────────────────────┤
│ TEST IMPLEMENTATION REQUIREMENTS:                              │
│                                                                 │
│ TESTING STRATEGY:                                              │
│ 1. Write unit tests alongside implementation                  │
│ 2. Test coverage must meet minimum requirements               │
│ 3. Integration tests for cross-component interactions         │
│ 4. Edge case and error condition testing                      │
│                                                                 │
│ COVERAGE REQUIREMENTS:                                         │
│ - Core business logic: 90%+ coverage                         │
│ - Controller methods: 85%+ coverage                          │
│ - Utility functions: 80%+ coverage                           │
│ - Integration points: 85%+ coverage                          │
│                                                                 │
│ TEST STRUCTURE:                                                │
│ - Unit tests in same package as implementation               │
│ - Integration tests in separate test package                 │
│ - Test files follow _test.go convention                      │
│ - Table-driven tests for multiple scenarios                  │
└─────────────────────────────────────────────────────────────────┘

```go
// Example test structure for implementation
package api_test

import (
    "testing"
    "github.com/stretchr/testify/assert"
    "github.com/stretchr/testify/require"
)

func TestResourceController_Reconcile(t *testing.T) {
    tests := []struct {
        name           string
        inputResource  *Resource
        expectedResult reconcile.Result
        expectedError  bool
        setupMocks     func(*MockClient)
    }{
        {
            name: "successful_reconciliation",
            inputResource: &Resource{
                ObjectMeta: metav1.ObjectMeta{
                    Name:      "test-resource",
                    Namespace: "default",
                },
                Spec: ResourceSpec{
                    Replicas: 3,
                },
            },
            expectedResult: reconcile.Result{},
            expectedError:  false,
            setupMocks: func(client *MockClient) {
                client.EXPECT().Get(gomock.Any(), gomock.Any(), gomock.Any()).Return(nil)
                client.EXPECT().Update(gomock.Any(), gomock.Any()).Return(nil)
            },
        },
        {
            name: "resource_not_found_creates_new",
            inputResource: &Resource{
                ObjectMeta: metav1.ObjectMeta{
                    Name:      "new-resource",
                    Namespace: "default",
                },
            },
            expectedResult: reconcile.Result{RequeueAfter: time.Minute * 5},
            expectedError:  false,
            setupMocks: func(client *MockClient) {
                client.EXPECT().Get(gomock.Any(), gomock.Any(), gomock.Any()).Return(apierrors.NewNotFound(schema.GroupResource{}, "new-resource"))
                client.EXPECT().Create(gomock.Any(), gomock.Any()).Return(nil)
            },
        },
    }

    for _, tt := range tests {
        t.Run(tt.name, func(t *testing.T) {
            // Setup
            mockClient := NewMockClient(t)
            tt.setupMocks(mockClient)
            
            controller := &ResourceController{
                Client: mockClient,
                Log:    logr.Discard(),
            }

            // Execute
            result, err := controller.Reconcile(context.TODO(), ctrl.Request{
                NamespacedName: types.NamespacedName{
                    Name:      tt.inputResource.Name,
                    Namespace: tt.inputResource.Namespace,
                },
            })

            // Assert
            if tt.expectedError {
                require.Error(t, err)
            } else {
                require.NoError(t, err)
            }
            assert.Equal(t, tt.expectedResult, result)
        })
    }
}

// Integration test example
func TestResourceController_Integration(t *testing.T) {
    testEnv := envtest.Environment{
        CRDDirectoryPaths: []string{
            filepath.Join("..", "config", "crd", "bases"),
        },
    }

    cfg, err := testEnv.Start()
    require.NoError(t, err)
    defer testEnv.Stop()

    // Test real reconciliation with real API server
    // ...
}
```

## Work Log Maintenance

┌─────────────────────────────────────────────────────────────────┐
│ RULE R018.0.0 - Progress Reporting                             │
│ Source: rule-library/RULE-REGISTRY.md#R018                     │
├─────────────────────────────────────────────────────────────────┤
│ WORK LOG REQUIREMENTS:                                         │
│                                                                 │
│ UPDATE FREQUENCY:                                              │
│ - Every 30-60 minutes during active implementation            │
│ - After completing each implementation plan section           │
│ - After each significant commit                               │
│ - When encountering and resolving issues                      │
│ - Before any size measurements                                │
│                                                                 │
│ LOG ENTRY CONTENT:                                             │
│ - Timestamp of work session                                   │
│ - Specific tasks completed                                    │
│ - Current line count and size status                         │
│ - Test coverage achieved                                      │
│ - Issues encountered and resolutions                          │
│ - Next planned activities                                     │
└─────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────┐
│ RULE R170.0.0 - Work Log Template Usage                       │
│ Source: rule-library/RULE-REGISTRY.md#R170                    │
├─────────────────────────────────────────────────────────────────┤
│ MANDATORY WORK LOG USAGE:                                      │
│                                                                │
│ On Starting Implementation:                                   │
│ 1. VERIFY work-log.md exists:                                │
│    ```bash                                                   │
│    ls efforts/phase[N]/wave[N]/effort[N]/work-log.md        │
│    ```                                                       │
│                                                                │
│ 2. If missing, copy from template:                           │
│    ```bash                                                   │
│    cp templates/WORK-LOG-TEMPLATE.md ./work-log.md          │
│    ```                                                       │
│                                                                │
│ 3. Initialize work log:                                      │
│    - Fill in effort ID and name                             │
│    - Set target metrics from implementation plan            │
│    - Record start date/time                                 │
│                                                                │
│ Daily Updates (from template):                              │
│ - Use "Daily Log" section format                            │
│ - Update "Progress Summary" table                           │
│ - Fill "Implementation Checkpoints" at 25/50/75/100%       │
│ - Record in "Size Tracking" table                          │
│ - Document in "Issues and Resolutions" section             │
│                                                                │
│ Completion Requirements:                                     │
│ - "Completion Checklist" fully checked                      │
│ - "Final Metrics" section filled                           │
│ - "Review Feedback" section ready                          │
└─────────────────────────────────────────────────────────────────┘

```markdown
# Work Log Template Entry

## [2025-08-23 14:30] Implementation Session
**Duration**: 1.5 hours
**Focus**: Controller reconciliation logic

### Completed Tasks
- ✅ Implemented ResourceController struct and basic scaffolding
- ✅ Added reconciliation logic for CREATE operations  
- ✅ Implemented status update handling
- ✅ Added error handling and retry logic

### Implementation Progress
- **Lines Added**: ~150 lines (total: 387/800)
- **Files Modified**: 
  - `pkg/controllers/resource_controller.go` (new, 298 lines)
  - `pkg/api/v1/resource_types.go` (modified, +89 lines)
- **Test Coverage**: 87% (unit tests for reconcile logic)

### Quality Metrics
- Size Check: ✅ 387/800 lines (48% of limit)
- Tests: ✅ 15 unit tests written and passing
- Linting: ✅ No linting issues
- Build: ✅ Clean build

### Issues Encountered
1. **Issue**: Client injection pattern unclear from implementation plan
   - **Resolution**: Reviewed existing controller patterns in codebase
   - **Time**: 20 minutes investigation + 15 minutes implementation

2. **Issue**: Status update causing infinite reconciliation loop
   - **Resolution**: Added status comparison before updating
   - **Time**: 30 minutes debugging + 10 minutes fix

### Next Session Plans
- [ ] Implement UPDATE operation reconciliation
- [ ] Add DELETE operation handling with finalizers
- [ ] Implement resource status conditions
- [ ] Add integration tests

### Notes
- Controller pattern consistent with existing codebase conventions
- May need to add webhook validation in later session
- Consider performance optimization if resource count grows large
```

## Implementation Plan Adherence

┌─────────────────────────────────────────────────────────────────┐
│ RULE R054.0.0 - Implementation Plan Creation                   │
│ Source: rule-library/RULE-REGISTRY.md#R054                     │
├─────────────────────────────────────────────────────────────────┤
│ PLAN ADHERENCE REQUIREMENTS:                                   │
│                                                                 │
│ MANDATORY COMPLIANCE:                                          │
│ - Follow implementation plan section order exactly            │
│ - Complete each planned task fully before moving to next      │
│ - Document any deviations with rationale                      │
│ - Update plan if discoveries require scope changes            │
│                                                                 │
│ SCOPE CHANGE PROTOCOL:                                         │
│ 1. Identify scope change need during implementation           │
│ 2. Document current progress and stopping point               │
│ 3. Calculate impact on size estimates                         │
│ 4. Request code reviewer guidance for significant changes     │
│ 5. Update implementation plan before proceeding               │
└─────────────────────────────────────────────────────────────────┘

```python
def validate_implementation_plan_adherence(work_dir):
    """Validate current implementation follows the plan"""
    
    plan_path = os.path.join(work_dir, 'IMPLEMENTATION-PLAN.md')
    worklog_path = os.path.join(work_dir, 'work-log.md')
    
    if not os.path.exists(plan_path):
        return {
            'valid': False,
            'error': 'Implementation plan not found',
            'action_required': 'Locate or create implementation plan'
        }
    
    plan_tasks = parse_implementation_plan_tasks(plan_path)
    completed_tasks = parse_work_log_completed_tasks(worklog_path)
    
    adherence_analysis = {
        'plan_tasks_total': len(plan_tasks),
        'tasks_completed': len(completed_tasks),
        'completion_percentage': (len(completed_tasks) / len(plan_tasks)) * 100 if plan_tasks else 0,
        'out_of_order_tasks': [],
        'scope_deviations': [],
        'missing_tasks': []
    }
    
    # Check for out-of-order completion
    planned_order = [task['order'] for task in plan_tasks]
    completed_order = [task['order'] for task in completed_tasks if task.get('order')]
    
    for i, completed_task_order in enumerate(completed_order[1:], 1):
        if completed_task_order < completed_order[i-1]:
            adherence_analysis['out_of_order_tasks'].append({
                'task_order': completed_task_order,
                'expected_after': completed_order[i-1]
            })
    
    # Check for scope deviations
    planned_task_names = {task['name'] for task in plan_tasks}
    completed_task_names = {task['name'] for task in completed_tasks}
    
    adherence_analysis['scope_deviations'] = list(completed_task_names - planned_task_names)
    adherence_analysis['missing_tasks'] = [
        task for task in plan_tasks 
        if task['name'] not in completed_task_names
    ]
    
    # Determine overall adherence status
    if adherence_analysis['scope_deviations'] or adherence_analysis['out_of_order_tasks']:
        adherence_status = 'DEVIATIONS_DETECTED'
    elif adherence_analysis['completion_percentage'] < 50:
        adherence_status = 'ON_TRACK_EARLY'
    elif adherence_analysis['completion_percentage'] < 90:
        adherence_status = 'ON_TRACK_PROGRESSING'
    else:
        adherence_status = 'ON_TRACK_NEAR_COMPLETION'
    
    return {
        'valid': len(adherence_analysis['scope_deviations']) == 0,
        'status': adherence_status,
        'analysis': adherence_analysis,
        'recommendations': generate_adherence_recommendations(adherence_analysis)
    }

def generate_adherence_recommendations(analysis):
    """Generate recommendations based on plan adherence analysis"""
    
    recommendations = []
    
    if analysis['out_of_order_tasks']:
        recommendations.append({
            'type': 'ORDER_CORRECTION',
            'message': 'Complete remaining tasks in planned order',
            'priority': 'MEDIUM'
        })
    
    if analysis['scope_deviations']:
        recommendations.append({
            'type': 'SCOPE_VALIDATION',
            'message': 'Document rationale for scope deviations or update plan',
            'priority': 'HIGH'
        })
    
    if analysis['completion_percentage'] > 80 and analysis['missing_tasks']:
        recommendations.append({
            'type': 'COMPLETION_FOCUS',
            'message': 'Focus on completing remaining planned tasks',
            'priority': 'HIGH'
        })
    
    return recommendations
```

## Code Quality Standards

┌─────────────────────────────────────────────────────────────────┐
│ RULE R037.0.0 - Pattern Compliance                             │
│ Source: rule-library/RULE-REGISTRY.md#R037                     │
├─────────────────────────────────────────────────────────────────┤
│ PATTERN COMPLIANCE REQUIREMENTS:                               │
│                                                                 │
│ KUBERNETES PATTERNS:                                           │
│ - Controllers follow controller-runtime patterns              │
│ - Resources implement runtime.Object interface                │
│ - Status conditions follow standard conventions               │
│ - Finalizers implemented correctly for cleanup                │
│                                                                 │
│ KCP PATTERNS:                                                  │
│ - Multi-tenancy implemented with logical clusters             │
│ - Authorization uses RBAC with cluster-scoped permissions     │
│ - API grouping follows KCP conventions                        │
│ - Resource scheduling aware of workspace context              │
│                                                                 │
│ GO CODE PATTERNS:                                              │
│ - Error handling with wrapped errors                          │
│ - Context propagation through call chains                     │
│ - Structured logging with contextual fields                   │
│ - Interface-based design for testability                      │
└─────────────────────────────────────────────────────────────────┘

```go
// Example of KCP-aware controller implementation
type ResourceController struct {
    client.Client
    Log    logr.Logger
    Scheme *runtime.Scheme
}

func (r *ResourceController) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) {
    log := r.Log.WithValues("resource", req.NamespacedName)
    log.V(1).Info("Starting reconciliation")

    // Get the resource
    var resource myapi.Resource
    if err := r.Get(ctx, req.NamespacedName, &resource); err != nil {
        if apierrors.IsNotFound(err) {
            // Resource deleted, cleanup if needed
            log.V(1).Info("Resource not found, assuming deleted")
            return ctrl.Result{}, nil
        }
        return ctrl.Result{}, fmt.Errorf("failed to get resource: %w", err)
    }

    // Check if resource is being deleted
    if !resource.DeletionTimestamp.IsZero() {
        return r.handleDeletion(ctx, &resource, log)
    }

    // Add finalizer if not present
    if !controllerutil.ContainsFinalizer(&resource, myapi.ResourceFinalizer) {
        controllerutil.AddFinalizer(&resource, myapi.ResourceFinalizer)
        return r.updateResource(ctx, &resource, log)
    }

    // Main reconciliation logic
    result, err := r.reconcileResource(ctx, &resource, log)
    if err != nil {
        // Update status with error condition
        r.updateStatusCondition(&resource, myapi.ConditionTypeReady, metav1.ConditionFalse, 
            myapi.ReasonReconcileError, err.Error())
        if statusErr := r.Status().Update(ctx, &resource); statusErr != nil {
            log.Error(statusErr, "Failed to update status")
        }
        return result, fmt.Errorf("reconciliation failed: %w", err)
    }

    // Update status with success condition
    r.updateStatusCondition(&resource, myapi.ConditionTypeReady, metav1.ConditionTrue,
        myapi.ReasonReconcileSuccess, "Resource reconciled successfully")
    
    if err := r.Status().Update(ctx, &resource); err != nil {
        return ctrl.Result{}, fmt.Errorf("failed to update status: %w", err)
    }

    log.V(1).Info("Reconciliation completed successfully")
    return result, nil
}

func (r *ResourceController) reconcileResource(ctx context.Context, resource *myapi.Resource, log logr.Logger) (ctrl.Result, error) {
    // KCP-aware logic: Handle multi-tenant scenarios
    clusterName := logicalcluster.From(resource)
    log = log.WithValues("cluster", clusterName)
    
    // Implement main business logic here
    // ...
    
    return ctrl.Result{}, nil
}

func (r *ResourceController) updateStatusCondition(resource *myapi.Resource, conditionType string, status metav1.ConditionStatus, reason, message string) {
    condition := metav1.Condition{
        Type:               conditionType,
        Status:             status,
        LastTransitionTime: metav1.Now(),
        Reason:             reason,
        Message:            message,
    }
    
    meta.SetStatusCondition(&resource.Status.Conditions, condition)
}
```

## Commit Strategy

┌─────────────────────────────────────────────────────────────────┐
│ RULE R015.0.0 - Commit Message Format                          │
│ Source: rule-library/RULE-REGISTRY.md#R015                     │
├─────────────────────────────────────────────────────────────────┤
│ COMMIT FREQUENCY AND FORMAT:                                   │
│                                                                 │
│ COMMIT FREQUENCY:                                              │
│ - Every 1-2 hours of active development                       │
│ - After completing each implementation plan section           │
│ - Before any significant refactoring                          │
│ - When reaching size measurement milestones                   │
│                                                                 │
│ COMMIT MESSAGE FORMAT:                                         │
│ feat|fix|refactor|test: brief description (≤50 chars)        │
│                                                                 │
│ Optional body with details:                                   │
│ - What was implemented                                        │
│ - Size impact                                                 │
│ - Test coverage added                                         │
│ - Any architectural decisions                                 │
└─────────────────────────────────────────────────────────────────┘

```bash
# Example commit messages during implementation

# Feature commits
git commit -m "feat: add ResourceController reconciliation logic

- Implement basic CRUD reconciliation for Resource CRD
- Add error handling and retry mechanisms  
- Include status condition updates
- Size impact: +150 lines (387/800 total)
- Test coverage: 87% with 12 unit tests"

# Test commits  
git commit -m "test: add integration tests for ResourceController

- Add envtest-based integration test suite
- Test real reconciliation against k8s API server
- Cover edge cases and error conditions
- Size impact: +89 lines (476/800 total)
- Test coverage: 91% overall"

# Fix commits
git commit -m "fix: prevent infinite reconciliation loop in status updates

- Add status comparison before updating
- Only update status when actual changes detected
- Improves controller performance and reduces API calls
- No size impact (refactoring existing code)"
```

## State Transitions

From IMPLEMENTATION state:
- **SIZE_LIMIT_APPROACHED** → MEASURE_SIZE (Check exact size and plan next steps)
- **IMPLEMENTATION_COMPLETE** → TEST_WRITING (Focus on comprehensive testing)
- **ISSUES_ENCOUNTERED** → FIX_ISSUES (Address blocking problems)
- **SPLIT_REQUIRED** → SPLIT_WORK (Effort too large, needs splitting)
- **PLAN_DEVIATION** → CODE_REVIEW (Get guidance on scope changes)

## Early Warning System

```python
def monitor_implementation_health():
    """Monitor implementation progress for early warning signs"""
    
    current_dir = os.getcwd()
    
    health_indicators = {
        'size_trajectory': analyze_size_growth_trend(),
        'test_coverage': measure_current_test_coverage(),
        'plan_adherence': check_plan_adherence_status(),
        'commit_frequency': analyze_commit_frequency(),
        'issue_resolution_time': track_issue_resolution()
    }
    
    warnings = []
    
    # Size trajectory warning
    if health_indicators['size_trajectory']['projected_final_size'] > 750:
        warnings.append({
            'type': 'SIZE_WARNING',
            'message': f"Projected final size {health_indicators['size_trajectory']['projected_final_size']} lines may exceed limit",
            'action': 'Consider scope reduction or prepare for split'
        })
    
    # Test coverage warning  
    if health_indicators['test_coverage']['current_percentage'] < 80:
        warnings.append({
            'type': 'COVERAGE_WARNING',
            'message': f"Test coverage at {health_indicators['test_coverage']['current_percentage']:.1f}% below target",
            'action': 'Increase test coverage before proceeding'
        })
    
    # Plan adherence warning
    if health_indicators['plan_adherence']['deviation_score'] > 20:
        warnings.append({
            'type': 'PLAN_WARNING',
            'message': 'Significant deviation from implementation plan detected',
            'action': 'Review plan adherence or update plan'
        })
    
    return {
        'health_status': 'HEALTHY' if not warnings else 'WARNINGS_PRESENT',
        'indicators': health_indicators,
        'warnings': warnings,
        'next_checkpoint': 'In 200 lines or 1 hour of work'
    }
```